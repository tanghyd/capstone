{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.py\n",
      "helpers.py\n",
      "processing.py\n",
      "metadata.py\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "def display_ent(doc, style=\"ent\", colors=None, options=None, compact=True):\n",
    "    colors = colors or {\"TRIGGER\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}\n",
    "    options = options or {\"ents\": None, \"colors\": colors, \"compact\": compact}\n",
    "    displacy.render(doc, style=style, jupyter=True, options=options)\n",
    "\n",
    "from pipeline.utils.display import display_ent\n",
    "from pipeline.data.metadata import get_report_data, get_geoview_data\n",
    "from pipeline.preprocessing.processing import match_triggers, triggers_json_to_df, load_triggers, load_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added punctuation removal pipe\n",
      "Added geological entity matcher pipe\n",
      "Added trigger phrase matcher pipe\n",
      "Loading spaCy model with spaCy doc output.\n"
     ]
    }
   ],
   "source": [
    "# testing engineering for extracting triggers from entity ruler, rather than on matcher\n",
    "from pipeline.preprocessing.processing import load_spacy_model, create_trigger_ruler\n",
    "\n",
    "nlp = load_spacy_model(output_type='doc', trigger_matcher=True, lemmatizer=False, geological_matcher=True,\n",
    "                       stopword_removal=False, punctuation_removal=True, lemmatize_triggers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files as dict: 100%|██████████| 32646/32646 [00:02<00:00, 13712.93it/s]\n"
     ]
    }
   ],
   "source": [
    "capstone_files, files = get_report_data(count_sentences=True, return_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full sweep of all documents on triggers to build data manually\n",
    "# data = {file : [(idx, ent.text) for idx, doc in enumerate(nlp.pipe(\n",
    "#     sentences, disable=['ner'], n_process=1, cleanup=True, batch_size=10000))\n",
    "#     for ent in doc.ents if ent.label_ == 'TRIGGER'] for file, sentences in tqdm(\n",
    "#     files.items(), desc='Extracting TRIGGER entities from documents')}\n",
    "\n",
    "# from pipeline.preprocessing.processing import data_path\n",
    "# import json\n",
    "\n",
    "# with open(data_path / 'sentence_triggers.json', 'w+') as f:\n",
    "#     json.dump(data, f)\n",
    "\n",
    "# df = pd.DataFrame([\n",
    "#     {\"filename\": filename, \"idx\": int(match[0]), \"trigger\": match[1]} \n",
    "#     for filename, matches in data.items() for match in matches\n",
    "# ])\n",
    "\n",
    "# df.groupby(['filename','idx'])['trigger'].apply(\n",
    "#     lambda x : ', '.join(x).strip()).reset_index().rename(\n",
    "#     columns={'trigger':'triggers'})#.to_csv('extracted_triggers_grouped.csv', index_label='triggers_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File for daniel at /home/daniel/capstone/data/events/daniel_dataset.csv already exists. Loading file.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>anumber</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>report_type</th>\n",
       "      <th>idx</th>\n",
       "      <th>triggers</th>\n",
       "      <th>reviewed</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>19</td>\n",
       "      <td>prospect</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>43</td>\n",
       "      <td>anomalism, mineralization</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>53</td>\n",
       "      <td>supported, mineralization</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>84</td>\n",
       "      <td>extensive</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>123</td>\n",
       "      <td>presence of</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filename  anumber  sentence_count  \\\n",
       "index                                                                    \n",
       "0      a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "1      a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "2      a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "3      a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "4      a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "\n",
       "      report_type  idx                   triggers  reviewed  label confidence  \\\n",
       "index                                                                           \n",
       "0          Annual   19                   prospect     False  False        NaN   \n",
       "1          Annual   43  anomalism, mineralization     False  False        NaN   \n",
       "2          Annual   53  supported, mineralization     False  False        NaN   \n",
       "3          Annual   84                  extensive     False  False        NaN   \n",
       "4          Annual  123                presence of     False  False        NaN   \n",
       "\n",
       "       lower_bound  upper_bound  \n",
       "index                            \n",
       "0                0            0  \n",
       "1                0            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                0            0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify labellers\n",
    "users = ('daniel','charlie')\n",
    "dataset = {}\n",
    "\n",
    "### SPECIFY USER ###\n",
    "user = 'daniel'\n",
    "\n",
    "# get data from path given user\n",
    "from pathlib import Path\n",
    "base_path = Path('.')\n",
    "labelled_path = base_path / 'data' / 'events' / f'{user}_dataset.csv'\n",
    "\n",
    "# get geoview data\n",
    "geoview = get_geoview_data()\n",
    "\n",
    "# load triggers grouped by sentence_idx in each file - triggers are comma separated strings\n",
    "extracted_triggers = pd.read_csv(os.path.join('data','events', 'extracted_triggers_grouped.csv'), index_col=0)\n",
    "\n",
    "# merge capstone_file data with anumber data with extracted triggers, joined on filename\n",
    "source = capstone_files.merge(\n",
    "    geoview[['anumber','report_type']], on='anumber').merge(\n",
    "    extracted_triggers, on='filename')\n",
    "\n",
    "for usr in users:\n",
    "    if usr==user:\n",
    "        if os.path.isfile(labelled_path):\n",
    "            print(f'File for {user} at {labelled_path.resolve()} already exists. Loading file.')\n",
    "            dataset[user] = pd.read_csv(labelled_path, index_col=0)\n",
    "        else:\n",
    "            print(f'Creating new dataset for {user}.')\n",
    "            # create a dataset for each labeller based off the source data\n",
    "            dataset[user] = pd.DataFrame.from_dict(dict(\n",
    "                    source.to_dict(),\n",
    "                    **{'reviewed': {idx: False for idx in range(len(source))}},\n",
    "                    **{'label': {idx: False for idx in range(len(source))}},\n",
    "                    **{'confidence': {idx: None for idx in range(len(source))}},\n",
    "                    **{'lower_bound': {idx: 0 for idx in range(len(source))}},\n",
    "                    **{'upper_bound': {idx: 0 for idx in range(len(source))}}))\n",
    "\n",
    "dataset[user].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[user].to_csv(labelled_path, index=True, index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 10\n",
    "\n",
    "def stratify_source_data(source, n, prop=False, seed=None, stratify_col='report_type'):\n",
    "    if prop:  # if n is not a percentage/proportion\n",
    "        n /= len(source)  # calculate count of total\n",
    "    train_idx, test_idx, train_label, test_label = train_test_split(source.index, source.label,\n",
    "        test_size = n, random_state = seed, stratify = source[stratify_col])\n",
    "    \n",
    "    return train_idx, test_idx, train_label, test_label\n",
    "\n",
    "def get_indices(dataset, n=100, prop=False, seed=None):\n",
    "    _, indices, _, _ = stratify_source_data(dataset, n=n, prop=prop, seed=seed)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([285173,  31753,  30227, 286567, 416405, 348130,  34561, 250226,\n",
       "            328562, 260488, 567911,  69616, 544614, 574056, 224878, 227250,\n",
       "            274951, 128062,  67388, 265521, 399504, 418206, 371608, 420438,\n",
       "            580573, 445860, 576365, 305482, 366571, 418992, 125671, 254945,\n",
       "            252887, 473485,  75026, 494942, 273298, 389623, 428408, 234677,\n",
       "            186454,   9522, 317052, 474140, 489705,  27937,  12256,  90785,\n",
       "            396561, 233878, 457919,  36048, 373581, 351670, 562448, 432349,\n",
       "            296739, 122783, 438533,  38245, 459278, 160515, 310902, 236782,\n",
       "            521023,  42288,  82548, 397568,  34739, 241805, 500298, 362601,\n",
       "            187693, 139632, 141635, 200441, 107321,  72599, 359250,  66518,\n",
       "            530654, 145245, 533011, 286590, 317323, 243648, 454060, 380886,\n",
       "            307495, 392814, 537632, 288754, 524681, 503291,  51687,  28457,\n",
       "            290536, 432115, 566544,  28232],\n",
       "           dtype='int64', name='index')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indices from stratified sampling procedure - make sure to set seed for consistent\n",
    "batch_size = 100\n",
    "batch_indices = get_indices(dataset[user], n=batch_size, seed=seed)\n",
    "batch_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 34561, 250226, 328562, 260488, 567911,  69616, 544614, 574056,\n",
       "            224878, 227250, 274951, 128062,  67388, 265521, 399504, 418206,\n",
       "            371608, 420438, 580573, 445860, 576365, 305482, 366571, 418992,\n",
       "            125671, 254945, 252887, 473485,  75026, 494942, 273298, 389623,\n",
       "            428408, 234677, 186454,   9522, 317052, 474140, 489705,  27937,\n",
       "             12256,  90785, 396561, 233878, 457919,  36048, 373581, 351670,\n",
       "            562448, 432349, 296739, 122783, 438533,  38245, 459278, 160515,\n",
       "            310902, 236782, 521023,  42288,  82548, 397568,  34739, 241805,\n",
       "            500298, 362601, 187693, 139632, 141635, 200441, 107321,  72599,\n",
       "            359250,  66518, 530654, 145245, 533011, 286590, 317323, 243648,\n",
       "            454060, 380886, 307495, 392814, 537632, 288754, 524681, 503291,\n",
       "             51687,  28457, 290536, 432115, 566544,  28232],\n",
       "           dtype='int64', name='index')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the user's dataset given the sampled indices but with rows that have not been reviewed\n",
    "df = dataset[user].loc[batch_indices].loc[~dataset[user].reviewed]\n",
    "indices = df.index\n",
    "\n",
    "# indices in batch that havent been reviewed\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a74535bcf44233b2ca00bcf8181db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Current Index: 34561 / 580746</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8ebf811e3042ef870c7af72ca1d297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Trigger Words</h3><ul><li>mineralisation</li></ul>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8fbb9b3b4c4299a94c6709cd0957f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Text Chunk Settings</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db76a20466614329ab7a2b7139094e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=0, description='Previous', max=0, min=-10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd094af3a5e4efb842e15a34268a3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=0, description='Next', max=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a36df262b946b99eb9401026febc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Update Text Range', style=ButtonStyle()), Checkbox(value=True, description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03038e9b3fef4377976b6973a8a2d53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Update NER Display', style=ButtonStyle()), Checkbox(value=True, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de66626f870643f18f81bba8f2ddc205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Labeller</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c26131c1a841f2946d2919a8942106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='success', description='Near Miss Event', style=ButtonStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc2c8d0616944d6a6a8c5c111c83d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051c425a06e844c1be4348ae9353b550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Confidence', index=2, options=('Low', 'Medium', 'High'), tooltips=('An uncertain in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be935a2401f8483c8635d28e45ab578a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(display='none'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc2c8d0616944d6a6a8c5c111c83d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb418f51a444df58c90d591f2bdf4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc2c8d0616944d6a6a8c5c111c83d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31223c48314c4fbba632a551f6f69258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(display='none'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare data to review for user\n",
    "i = 0  # starting position in the list of indices sampled  (Saved to df functioning as sentence idx)\n",
    "prev = 0  # the stored number of sentences shown previous to the centre trigger sentence (Saved to df)\n",
    "fwd = 0  # the stored number of sentences shown after the centre trigger sentence (saved to df)\n",
    "event = df.loc[indices[i]]  # first event\n",
    "\n",
    "def get_index_text(idx):\n",
    "    return f\"<h3>Current Index: {indices[i]} / {len(source)}</h3>\"\n",
    "\n",
    "def get_trigger_text(idx):  \n",
    "    trigger_words = ''.join([f'<li>{w}</li>' for w in df.loc[idx,'triggers'].split(',')])\n",
    "    return f\"<h3>Trigger Words</h3><ul>{trigger_words}</ul>\"\n",
    "\n",
    "def yes_pressed(b):\n",
    "    label_sentence(label=True)\n",
    "\n",
    "def no_pressed(b):\n",
    "    label_sentence(label=False)\n",
    "    \n",
    "def revert_pressed(b):\n",
    "    revert_changes()\n",
    "\n",
    "def label_sentence(label):\n",
    "    global i\n",
    "\n",
    "    # get confidence from button\n",
    "    confidence = confidence_toggle.get_interact_value()\n",
    "    \n",
    "    # assign data\n",
    "    df.loc[indices[i], 'reviewed'] = True\n",
    "    df.loc[indices[i], 'label'] = label\n",
    "    df.loc[indices[i], 'confidence'] = confidence\n",
    "\n",
    "    # save lower_idx and upper_idx\n",
    "    if save_chunk_toggle.get_interact_value():\n",
    "        df.loc[indices[i], 'lower_bound'] = prev_input.value\n",
    "        df.loc[indices[i], 'upper_bound'] = fwd_input.value\n",
    "        \n",
    "    # increment to next index\n",
    "    i += 1\n",
    "    \n",
    "    event = df.loc[indices[i]]  # get index position, not loc\n",
    "    idx_text.value = get_index_text(indices[i])\n",
    "    confidence_toggle.value = 'High'\n",
    "    triggers_widget.value = get_trigger_text(indices[i])\n",
    "    prev_input.value = 0\n",
    "    fwd_input.value = 0\n",
    "\n",
    "    # sentence_text = files[event.filename][event.idx]\n",
    "    with event_output:\n",
    "        event_output.clear_output()\n",
    "        \n",
    "        display_ent([nlp(files[event.filename][event.idx])])\n",
    "        \n",
    "    with prev_output:\n",
    "        prev_output.clear_output()\n",
    "        prev_output.layout.display = \"none\"\n",
    "\n",
    "    with fwd_output:\n",
    "        fwd_output.clear_output()\n",
    "        fwd_output.layout.display = \"none\"\n",
    "        \n",
    "def revert_changes():\n",
    "    global i\n",
    "    global prev\n",
    "    global fwd\n",
    "    \n",
    "    # get data from toggle button\n",
    "    confidence = confidence_toggle.get_interact_value()\n",
    "    \n",
    "    # revert idx back one\n",
    "    i -= 1\n",
    "    \n",
    "    # reset data\n",
    "    df.loc[indices[i], 'reviewed'] = False\n",
    "    df.loc[indices[i], 'label'] = False\n",
    "    df.loc[indices[i], 'confidence'] = None\n",
    "    df.loc[indices[i], 'lower_bound'] = 0\n",
    "    df.loc[indices[i], 'upper_bound'] = 0\n",
    "    \n",
    "    # get event\n",
    "    event = df.loc[indices[i]]\n",
    "    \n",
    "    # update widget values\n",
    "    idx_text.value = get_index_text(indices[i])\n",
    "    confidence_toggle.value = 'High'\n",
    "    triggers_widget.value = get_trigger_text(indices[i])\n",
    "    prev_input.value = 0\n",
    "    fwd_input.value = 0\n",
    "\n",
    "    # sentence_text = files[event.filename][event.idx]\n",
    "    with event_output:\n",
    "        event_output.clear_output()\n",
    "        \n",
    "        display_ent([nlp(files[event.filename][event.idx])])\n",
    "        \n",
    "    with prev_output:\n",
    "        prev_output.clear_output()\n",
    "        prev_output.layout.display = \"none\"\n",
    "\n",
    "    with fwd_output:\n",
    "        fwd_output.clear_output()\n",
    "        fwd_output.layout.display = \"none\"\n",
    "\n",
    "def save_pressed(b):\n",
    "    # print('Dataset saved.')\n",
    "    dataset[user].loc[indices] = df\n",
    "    dataset[user].to_csv(labelled_path, index=True, index_label='index')\n",
    "\n",
    "idx_text = widgets.HTML(value=get_index_text(indices[i]))\n",
    "triggers_widget = widgets.HTML(value=get_trigger_text(indices[i]))\n",
    "line_break = widgets.HTML(value='\\n')\n",
    "\n",
    "prev_input = widgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=-10,\n",
    "    max=0,\n",
    "    step=1,\n",
    "    description='Previous',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "fwd_input = widgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Next',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def update_chunk(b):\n",
    "    global i\n",
    "    global prev\n",
    "    global fwd\n",
    "    \n",
    "    event = df.loc[indices[i]]\n",
    "    \n",
    "    prev = prev_input.value\n",
    "    fwd = fwd_input.value\n",
    "\n",
    "    with prev_output:\n",
    "        if prev < 0:\n",
    "            prev_output.clear_output()\n",
    "            prev_chunk = list(nlp.pipe(files[event.filename][event.idx + prev : event.idx]))\n",
    "            display_ent(prev_chunk)\n",
    "            prev_output.layout.display = \"block\"\n",
    "        else:\n",
    "            prev_output.layout.display = 'none'\n",
    "        \n",
    "    with fwd_output:\n",
    "        if fwd > 0:\n",
    "            fwd_output.clear_output()\n",
    "            fwd_chunk = list(nlp.pipe(files[event.filename][event.idx + 1 : event.idx + 1 + fwd]))\n",
    "            display_ent(fwd_chunk)\n",
    "            fwd_output.layout.display = \"block\"\n",
    "        else:        \n",
    "            fwd_output.layout.display = 'none'\n",
    "\n",
    "def toggle_ner(toggle):\n",
    "    global idx\n",
    "    global prev\n",
    "    global fwd\n",
    "    \n",
    "    toggle = ner_toggle.get_interact_value()\n",
    "    \n",
    "    prev = prev_input.value\n",
    "    fwd = fwd_input.value\n",
    "    \n",
    "    if prev < 0:\n",
    "        with prev_output:\n",
    "            prev_chunk = list(nlp.pipe(files[event.filename][event.idx + prev : event.idx]))\n",
    "            if toggle:\n",
    "                prev_output.clear_output()\n",
    "                display_ent(prev_chunk)\n",
    "            else:\n",
    "                prev_chunk_text = ' '.join([token.text for token in prev_chunk]).strip()\n",
    "                prev_output.clear_output()\n",
    "                display(prev_chunk_text)\n",
    "                \n",
    "            prev_output.layout.display = \"block\"\n",
    "            \n",
    "    if fwd > 0:\n",
    "        with fwd_output:\n",
    "            fwd_chunk = list(nlp.pipe(files[event.filename][event.idx + 1 : event.idx + 1 + fwd]))\n",
    "            if toggle:\n",
    "                fwd_output.clear_output()\n",
    "                display_ent(fwd_chunk)\n",
    "            else:\n",
    "                fwd_chunk_text = ' '.join([token.text for token in fwd_chunk]).strip()\n",
    "                fwd_output.clear_output()\n",
    "                display(fwd_chunk_text)\n",
    "                \n",
    "            fwd_output.layout.display = \"block\"\n",
    "            \n",
    "prev_output = widgets.Output()\n",
    "event_output = widgets.Output()\n",
    "fwd_output = widgets.Output()\n",
    "\n",
    "prev_output.layout.display = \"none\"\n",
    "fwd_output.layout.display = \"none\"\n",
    "\n",
    "yes = widgets.Button(description='Near Miss Event', button_style='success')\n",
    "yes.on_click(yes_pressed)\n",
    "\n",
    "no = widgets.Button(description='Not Near Miss Event', button_style='danger')\n",
    "no.on_click(no_pressed)\n",
    "\n",
    "save = widgets.Button(description='Save DataFrame', button_style='primary')\n",
    "save.on_click(save_pressed)\n",
    "\n",
    "revert = widgets.Button(description='Revert Index', button_style='warning')\n",
    "revert.on_click(revert_pressed)\n",
    "\n",
    "update = widgets.Button(description='Update Text Range', button_style='')\n",
    "update.on_click(update_chunk)\n",
    "\n",
    "update_ner = widgets.Button(description='Update NER Display', button_style='')\n",
    "update_ner.on_click(toggle_ner)\n",
    "\n",
    "ner_toggle = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='External NER',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "confidence_toggle = widgets.ToggleButtons(\n",
    "    options=['Low', 'Medium', 'High'],\n",
    "    value='High',\n",
    "    description='Confidence',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltips=[\n",
    "        'An uncertain interpretation worth reviewing',\n",
    "        'A reasonable interpretation of a near miss',\n",
    "        'A certain interpretation of a near miss'],\n",
    ")\n",
    "\n",
    "save_chunk_toggle = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Save Text Chunk Bounds',\n",
    "    disabled=False,\n",
    "    #button_style='info',\n",
    "    #tooltip='Saves lower and upper bound indices on text chunks'\n",
    ")\n",
    "\n",
    "settings_text =  widgets.HTML(value=\"<h3>Text Chunk Settings</h3>\")\n",
    "labeller_text = widgets.HTML(value=\"<h3>Labeller</h3>\")\n",
    "\n",
    "#text_chunk_box = widgets.VBox([settings_text, save_chunk_toggle])\n",
    "\n",
    "text_buttons = widgets.HBox([update, save_chunk_toggle])\n",
    "ner_buttons = widgets.HBox([update_ner, ner_toggle])\n",
    "label_buttons = widgets.HBox([yes, no])\n",
    "function_buttons = widgets.HBox([save, revert])\n",
    "buttons = widgets.VBox([label_buttons, function_buttons])\n",
    "\n",
    "with event_output:\n",
    "    display_ent(nlp(files[event.filename][event.idx]))\n",
    "    \n",
    "with prev_output:\n",
    "    display(widgets.HTML(value='\\n'))\n",
    "\n",
    "with fwd_output:\n",
    "    display(widgets.HTML(value=''))\n",
    "                            \n",
    "display(idx_text, triggers_widget, settings_text, prev_input, fwd_input, text_buttons, ner_buttons,\n",
    "        labeller_text, buttons, line_break, confidence_toggle, prev_output, line_break, event_output, \n",
    "        line_break, fwd_output,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>anumber</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>report_type</th>\n",
       "      <th>idx</th>\n",
       "      <th>triggers</th>\n",
       "      <th>reviewed</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34561</th>\n",
       "      <td>a080552_gindalbie 2008 annual report_17729535....</td>\n",
       "      <td>80552</td>\n",
       "      <td>175</td>\n",
       "      <td>Annual</td>\n",
       "      <td>69</td>\n",
       "      <td>mineralisation</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                filename  anumber  \\\n",
       "index                                                               \n",
       "34561  a080552_gindalbie 2008 annual report_17729535....    80552   \n",
       "\n",
       "       sentence_count report_type  idx        triggers  reviewed  label  \\\n",
       "index                                                                     \n",
       "34561             175      Annual   69  mineralisation      True  False   \n",
       "\n",
       "      confidence  lower_bound  upper_bound  \n",
       "index                                       \n",
       "34561       High            0            0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df is temp data store for your data - shown below\n",
    "df.loc[df.reviewed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>anumber</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>report_type</th>\n",
       "      <th>idx</th>\n",
       "      <th>triggers</th>\n",
       "      <th>reviewed</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34561</th>\n",
       "      <td>a080552_gindalbie 2008 annual report_17729535....</td>\n",
       "      <td>80552</td>\n",
       "      <td>175</td>\n",
       "      <td>Annual</td>\n",
       "      <td>69</td>\n",
       "      <td>mineralisation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                filename  anumber  \\\n",
       "index                                                               \n",
       "34561  a080552_gindalbie 2008 annual report_17729535....    80552   \n",
       "\n",
       "       sentence_count report_type  idx        triggers  reviewed  label  \\\n",
       "index                                                                     \n",
       "34561             175      Annual   69  mineralisation     False  False   \n",
       "\n",
       "      confidence  lower_bound  upper_bound  \n",
       "index                                       \n",
       "34561        NaN            0            0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset[user] is your main dataset, indices are the current indices being labelled\n",
    "# note that df does not get saved unless you manually overwrite!\n",
    "dataset[user].loc[df.loc[df.reviewed].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save backup\n",
    "dataset[user].loc[indices] = df\n",
    "dataset[user].to_csv(os.path.join('data','events',f'{user}_dataset_backup.csv'), index=True, index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
