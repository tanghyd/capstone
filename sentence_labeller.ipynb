{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier.py\n",
      "helpers.py\n",
      "processing.py\n",
      "metadata.py\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "def display_ent(doc, style=\"ent\", colors=None, options=None, compact=True):\n",
    "    colors = colors or {\"TRIGGER\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\"}\n",
    "    options = options or {\"ents\": None, \"colors\": colors, \"compact\": compact}\n",
    "    displacy.render(doc, style=style, jupyter=True, options=options)\n",
    "\n",
    "from pipeline.utils.display import display_ent\n",
    "from pipeline.data.metadata import get_report_data, get_geoview_data\n",
    "from pipeline.preprocessing.processing import match_triggers, triggers_json_to_df, load_triggers, load_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added punctuation removal pipe\n",
      "Added trigger phrase matcher pipe\n",
      "Loading spaCy model with spaCy doc output.\n"
     ]
    }
   ],
   "source": [
    "# testing engineering for extracting triggers from entity ruler, rather than on matcher\n",
    "from pipeline.preprocessing.processing import load_spacy_model, create_trigger_ruler\n",
    "\n",
    "nlp = load_spacy_model(output_type='doc', trigger_matcher=True, lemmatizer=False, geological_matcher=False,\n",
    "                       stopword_removal=False, punctuation_removal=True, lemmatize_triggers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files as dict: 100%|██████████| 32646/32646 [00:02<00:00, 14598.25it/s]\n"
     ]
    }
   ],
   "source": [
    "capstone_files, files = get_report_data(count_sentences=True, return_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full sweep of all documents on triggers to build data manually\n",
    "# data = {file : [(idx, ent.text) for idx, doc in enumerate(nlp.pipe(\n",
    "#     sentences, disable=['ner'], n_process=1, cleanup=True, batch_size=10000))\n",
    "#     for ent in doc.ents if ent.label_ == 'TRIGGER'] for file, sentences in tqdm(\n",
    "#     files.items(), desc='Extracting TRIGGER entities from documents')}\n",
    "\n",
    "# from pipeline.preprocessing.processing import data_path\n",
    "# import json\n",
    "\n",
    "# with open(data_path / 'sentence_triggers.json', 'w+') as f:\n",
    "#     json.dump(data, f)\n",
    "\n",
    "# df = pd.DataFrame([\n",
    "#     {\"filename\": filename, \"idx\": int(match[0]), \"trigger\": match[1]} \n",
    "#     for filename, matches in data.items() for match in matches\n",
    "# ])\n",
    "\n",
    "# df.groupby(['filename','idx'])['trigger'].apply(\n",
    "#     lambda x : ', '.join(x).strip()).reset_index().rename(\n",
    "#     columns={'trigger':'triggers'})#.to_csv('extracted_triggers_grouped.csv', index_label='triggers_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>anumber</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>report_type</th>\n",
       "      <th>idx</th>\n",
       "      <th>triggers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>19</td>\n",
       "      <td>prospect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>43</td>\n",
       "      <td>anomalism, mineralization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>53</td>\n",
       "      <td>supported, mineralization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>84</td>\n",
       "      <td>extensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>123</td>\n",
       "      <td>presence of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 filename  anumber  sentence_count  \\\n",
       "0  a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "1  a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "2  a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "3  a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "4  a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "\n",
       "  report_type  idx                   triggers  \n",
       "0      Annual   19                   prospect  \n",
       "1      Annual   43  anomalism, mineralization  \n",
       "2      Annual   53  supported, mineralization  \n",
       "3      Annual   84                  extensive  \n",
       "4      Annual  123                presence of  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geoview = get_geoview_data()\n",
    "\n",
    "# load triggers grouped by sentence_idx in each file - triggers are comma separated strings\n",
    "extracted_triggers = pd.read_csv(os.path.join('data','events', 'extracted_triggers_grouped.csv'), index_col=0)\n",
    "\n",
    "# merge capstone_file data with anumber data with extracted triggers, joined on filename\n",
    "source = capstone_files.merge(\n",
    "    geoview[['anumber','report_type']], on='anumber').merge(\n",
    "    extracted_triggers, on='filename')\n",
    "\n",
    "# display source data\n",
    "source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File for charlie at /home/daniel/capstone/data/events/charlie_dataset.csv already exists. Loading file.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>anumber</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>report_type</th>\n",
       "      <th>idx</th>\n",
       "      <th>triggers</th>\n",
       "      <th>reviewed</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>19</td>\n",
       "      <td>prospect</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>43</td>\n",
       "      <td>anomalism, mineralization</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>53</td>\n",
       "      <td>supported, mineralization</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>84</td>\n",
       "      <td>extensive</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a074282_reidy_annual2006_12863956.json</td>\n",
       "      <td>74282</td>\n",
       "      <td>141</td>\n",
       "      <td>Annual</td>\n",
       "      <td>123</td>\n",
       "      <td>presence of</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filename  anumber  sentence_count  \\\n",
       "index                                                                    \n",
       "0      a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "1      a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "2      a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "3      a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "4      a074282_reidy_annual2006_12863956.json    74282             141   \n",
       "\n",
       "      report_type  idx                   triggers  reviewed  label  \\\n",
       "index                                                                \n",
       "0          Annual   19                   prospect     False  False   \n",
       "1          Annual   43  anomalism, mineralization     False  False   \n",
       "2          Annual   53  supported, mineralization     False  False   \n",
       "3          Annual   84                  extensive     False  False   \n",
       "4          Annual  123                presence of     False  False   \n",
       "\n",
       "       confidence  lower_bound  upper_bound  \n",
       "index                                        \n",
       "0             NaN            0            0  \n",
       "1             NaN            0            0  \n",
       "2             NaN            0            0  \n",
       "3             NaN            0            0  \n",
       "4             NaN            0            0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify labellers\n",
    "users = ('daniel','charlie')\n",
    "dataset = {}\n",
    "\n",
    "### SPECIFY USER ###\n",
    "user = 'charlie'\n",
    "\n",
    "# get data from path given user\n",
    "from pathlib import Path\n",
    "base_path = Path('.')\n",
    "labelled_path = base_path / 'data' / 'events' / f'{user}_dataset.csv'\n",
    "\n",
    "for usr in users:\n",
    "    if usr==user:\n",
    "        if os.path.isfile(labelled_path):\n",
    "            print(f'File for {user} at {labelled_path.resolve()} already exists. Loading file.')\n",
    "            dataset[user] = pd.read_csv(labelled_path, index_col=0)\n",
    "        else:\n",
    "            print(f'Creating new dataset for {user}.')\n",
    "            # create a dataset for each labeller based off the source data\n",
    "            dataset[user] = pd.DataFrame.from_dict(dict(\n",
    "                    source.to_dict(),\n",
    "                    **{'reviewed': {idx: False for idx in range(len(source))}},\n",
    "                    **{'label': {idx: False for idx in range(len(source))}},\n",
    "                    **{'confidence': {idx: None for idx in range(len(source))}},\n",
    "                    **{'lower_bound': {idx: 0 for idx in range(len(source))}},\n",
    "                    **{'upper_bound': {idx: 0 for idx in range(len(source))}}))\n",
    "\n",
    "dataset[user].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[user].to_csv(labelled_path, index=True, index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 1\n",
    "\n",
    "def stratify_source_data(source, n, prop=False, seed=None, stratify_col='report_type'):\n",
    "    if prop:  # if n is not a percentage/proportion\n",
    "        n /= len(source)  # calculate count of total\n",
    "    train_idx, test_idx, train_label, test_label = train_test_split(source.index, source.label,\n",
    "        test_size = n, random_state = seed, stratify = source[stratify_col])\n",
    "    \n",
    "    return train_idx, test_idx, train_label, test_label\n",
    "\n",
    "def get_indices(dataset, n=100, prop=False, seed=None):\n",
    "    _, indices, _, _ = stratify_source_data(dataset, n=n, prop=prop, seed=seed)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([532931, 523097, 355152, 276101, 390913, 208675, 395272, 265797,\n",
       "            575037,  69689, 121726, 128143, 173377, 458102, 450338,  38181,\n",
       "            191079,  35443, 496615, 225020, 394485, 392208, 480358, 234691,\n",
       "            511076, 431132, 267625, 224314, 576125, 287377, 101796, 236045,\n",
       "            484381, 475250, 314849, 570322, 362909,  52756, 357674, 175385,\n",
       "            171135, 124540, 549955, 150851, 136003, 294112, 133431, 307573,\n",
       "            376212,  21735, 223265,  68167, 330087, 415349, 135993, 192129,\n",
       "             72182, 197928, 551341, 569124, 262790,  29297, 517991, 486495,\n",
       "            257661, 292355,  78745, 437833, 490385, 397661, 157226, 535087,\n",
       "            491340, 493256,   1446, 251355,  74487, 161471, 177376, 261531,\n",
       "            157255,  34201, 542703,  24731,  98896, 296854,  28801,  94085,\n",
       "            201257, 400822, 398959, 474487, 172004, 449215, 235744, 133884,\n",
       "            123886, 279087, 252308, 534321],\n",
       "           dtype='int64', name='index')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get indices from stratified sampling procedure - make sure to set seed for consistent\n",
    "indices = get_indices(dataset[user], n=100, seed=seed)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>anumber</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>report_type</th>\n",
       "      <th>idx</th>\n",
       "      <th>triggers</th>\n",
       "      <th>reviewed</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>532931</th>\n",
       "      <td>a106392_unlock-e51_1063_2015s.json</td>\n",
       "      <td>106392</td>\n",
       "      <td>161</td>\n",
       "      <td>Final Surrender</td>\n",
       "      <td>117</td>\n",
       "      <td>broad</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523097</th>\n",
       "      <td>a078348_c125_2004_2008a_15517251.json</td>\n",
       "      <td>78348</td>\n",
       "      <td>247</td>\n",
       "      <td>Annual</td>\n",
       "      <td>195</td>\n",
       "      <td>mineralisation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355152</th>\n",
       "      <td>a079276_p29_1795_2008a_10208681.json</td>\n",
       "      <td>79276</td>\n",
       "      <td>72</td>\n",
       "      <td>Annual</td>\n",
       "      <td>64</td>\n",
       "      <td>mineralisation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276101</th>\n",
       "      <td>a081229_c117_1997_2009a_15776919.json</td>\n",
       "      <td>81229</td>\n",
       "      <td>13502</td>\n",
       "      <td>Annual</td>\n",
       "      <td>1396</td>\n",
       "      <td>broad</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390913</th>\n",
       "      <td>a098901_e77_1987_2013_a_16118961.json</td>\n",
       "      <td>98901</td>\n",
       "      <td>360</td>\n",
       "      <td>Annual</td>\n",
       "      <td>249</td>\n",
       "      <td>mineralisation</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133884</th>\n",
       "      <td>a088448_r206 2010_zuleika-kunanalling project_...</td>\n",
       "      <td>88448</td>\n",
       "      <td>539</td>\n",
       "      <td>Annual</td>\n",
       "      <td>505</td>\n",
       "      <td>proposed, prospect, broads</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123886</th>\n",
       "      <td>a099477_finalgeologicalreport2013ddh_july2013_...</td>\n",
       "      <td>99477</td>\n",
       "      <td>248</td>\n",
       "      <td>Co-Funded Drilling</td>\n",
       "      <td>233</td>\n",
       "      <td>support</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279087</th>\n",
       "      <td>a098683_e28-2096_2013 annual report_9919264.json</td>\n",
       "      <td>98683</td>\n",
       "      <td>439</td>\n",
       "      <td>Annual</td>\n",
       "      <td>278</td>\n",
       "      <td>extensive</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252308</th>\n",
       "      <td>a081794_annual technical report e21_124_lakesi...</td>\n",
       "      <td>81794</td>\n",
       "      <td>94</td>\n",
       "      <td>Annual</td>\n",
       "      <td>46</td>\n",
       "      <td>significant</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534321</th>\n",
       "      <td>a075110_p27-1575_2007 doir annual report_12078...</td>\n",
       "      <td>75110</td>\n",
       "      <td>234</td>\n",
       "      <td>Annual</td>\n",
       "      <td>167</td>\n",
       "      <td>mineralised</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 filename  anumber  \\\n",
       "index                                                                \n",
       "532931                 a106392_unlock-e51_1063_2015s.json   106392   \n",
       "523097              a078348_c125_2004_2008a_15517251.json    78348   \n",
       "355152               a079276_p29_1795_2008a_10208681.json    79276   \n",
       "276101              a081229_c117_1997_2009a_15776919.json    81229   \n",
       "390913              a098901_e77_1987_2013_a_16118961.json    98901   \n",
       "...                                                   ...      ...   \n",
       "133884  a088448_r206 2010_zuleika-kunanalling project_...    88448   \n",
       "123886  a099477_finalgeologicalreport2013ddh_july2013_...    99477   \n",
       "279087   a098683_e28-2096_2013 annual report_9919264.json    98683   \n",
       "252308  a081794_annual technical report e21_124_lakesi...    81794   \n",
       "534321  a075110_p27-1575_2007 doir annual report_12078...    75110   \n",
       "\n",
       "        sentence_count         report_type   idx                    triggers  \\\n",
       "index                                                                          \n",
       "532931             161     Final Surrender   117                       broad   \n",
       "523097             247              Annual   195              mineralisation   \n",
       "355152              72              Annual    64              mineralisation   \n",
       "276101           13502              Annual  1396                       broad   \n",
       "390913             360              Annual   249              mineralisation   \n",
       "...                ...                 ...   ...                         ...   \n",
       "133884             539              Annual   505  proposed, prospect, broads   \n",
       "123886             248  Co-Funded Drilling   233                     support   \n",
       "279087             439              Annual   278                   extensive   \n",
       "252308              94              Annual    46                 significant   \n",
       "534321             234              Annual   167                 mineralised   \n",
       "\n",
       "        reviewed  label  confidence  lower_bound  upper_bound  \n",
       "index                                                          \n",
       "532931     False  False         NaN            0            0  \n",
       "523097     False  False         NaN            0            0  \n",
       "355152     False  False         NaN            0            0  \n",
       "276101     False  False         NaN            0            0  \n",
       "390913     False  False         NaN            0            0  \n",
       "...          ...    ...         ...          ...          ...  \n",
       "133884     False  False         NaN            0            0  \n",
       "123886     False  False         NaN            0            0  \n",
       "279087     False  False         NaN            0            0  \n",
       "252308     False  False         NaN            0            0  \n",
       "534321     False  False         NaN            0            0  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the user's dataset given the sampled indices but with rows that have not been reviewed\n",
    "df = dataset[user].loc[indices].loc[~dataset[user].reviewed]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56cebc88f5e438ab3d1cf3dcea3def6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Current Index: 532931 / 100</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b374030beb4be89764a9fe06c276d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Trigger Words</h3><ul><li>broad</li></ul>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f59c1e7f84423dad81cf8cbaa40613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Text Chunk Settings</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad2e721eab34319bc32370cd5317c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=0, description='Previous', max=0, min=-10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213a5d1ee1a54d61b4bcaef56101db12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedIntText(value=0, description='Next', max=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f32a2a5fa4f4d1eb8ba5d56817872f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Update Text Range', style=ButtonStyle()), Checkbox(value=True, description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd66b8af364d4041b10bac218da3ca11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Update NER Display', style=ButtonStyle()), Checkbox(value=True, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81565d66c4a14d5587ecbf50485899bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Labeller</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb643135067d458989b605c089d4cedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='success', description='Near Miss Event', style=ButtonStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1573d90181f8431d9d1a2f43f5fbba22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80de7ffff50a4dc180221dd5902a5fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Confidence', index=2, options=('Low', 'Medium', 'High'), tooltips=('An uncertain in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0d1d4a8601488693d852796e6dfa27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(display='none'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1573d90181f8431d9d1a2f43f5fbba22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00242f31f16047aeae4cefbbe9235a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1573d90181f8431d9d1a2f43f5fbba22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864af5c22e1a43b4ac66ced1497169d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(display='none'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare data to review for user\n",
    "i = 0  # starting position in the list of indices sampled  (Saved to df functioning as sentence idx)\n",
    "prev = 0  # the stored number of sentences shown previous to the centre trigger sentence (Saved to df)\n",
    "fwd = 0  # the stored number of sentences shown after the centre trigger sentence (saved to df)\n",
    "event = df.loc[indices[i]]  # first event\n",
    "\n",
    "def get_index_text(idx):\n",
    "    return f\"<h3>Current Index: {indices[i]} / {len(source)}</h3>\"\n",
    "\n",
    "def get_trigger_text(idx):  \n",
    "    trigger_words = ''.join([f'<li>{w}</li>' for w in df.loc[idx,'triggers'].split(',')])\n",
    "    return f\"<h3>Trigger Words</h3><ul>{trigger_words}</ul>\"\n",
    "\n",
    "def yes_pressed(b):\n",
    "    label_sentence(label=True)\n",
    "\n",
    "def no_pressed(b):\n",
    "    label_sentence(label=False)\n",
    "    \n",
    "def revert_pressed(b):\n",
    "    revert_changes()\n",
    "\n",
    "def label_sentence(label):\n",
    "    global i\n",
    "\n",
    "    # get confidence from button\n",
    "    confidence = confidence_toggle.get_interact_value()\n",
    "    \n",
    "    # assign data\n",
    "    df.loc[indices[i], 'reviewed'] = True\n",
    "    df.loc[indices[i], 'label'] = label\n",
    "    df.loc[indices[i], 'confidence'] = confidence\n",
    "\n",
    "    # save lower_idx and upper_idx\n",
    "    if save_chunk_toggle.get_interact_value():\n",
    "        df.loc[indices[i], 'lower_bound'] = prev_input.value\n",
    "        df.loc[indices[i], 'upper_bound'] = fwd_input.value\n",
    "        \n",
    "    # increment to next index\n",
    "    i += 1\n",
    "    \n",
    "    event = df.loc[indices[i]]  # get index position, not loc\n",
    "    idx_text.value = get_index_text(indices[i])\n",
    "    confidence_toggle.value = 'High'\n",
    "    triggers_widget.value = get_trigger_text(indices[i])\n",
    "    prev_input.value = 0\n",
    "    fwd_input.value = 0\n",
    "\n",
    "    # sentence_text = files[event.filename][event.idx]\n",
    "    with event_output:\n",
    "        event_output.clear_output()\n",
    "        \n",
    "        display_ent([nlp(files[event.filename][event.idx])])\n",
    "        \n",
    "    with prev_output:\n",
    "        prev_output.clear_output()\n",
    "        prev_output.layout.display = \"none\"\n",
    "\n",
    "    with fwd_output:\n",
    "        fwd_output.clear_output()\n",
    "        fwd_output.layout.display = \"none\"\n",
    "        \n",
    "def revert_changes():\n",
    "    global i\n",
    "    global prev\n",
    "    global fwd\n",
    "    \n",
    "    # get data from toggle button\n",
    "    confidence = confidence_toggle.get_interact_value()\n",
    "    \n",
    "    # revert idx back one\n",
    "    i -= 1\n",
    "    \n",
    "    # reset data\n",
    "    df.loc[indices[i], 'reviewed'] = False\n",
    "    df.loc[indices[i], 'label'] = False\n",
    "    df.loc[indices[i], 'confidence'] = None\n",
    "    df.loc[indices[i], 'lower_idx'] = 0\n",
    "    df.loc[indices[i], 'upper_idx'] = 0\n",
    "    \n",
    "    # get event\n",
    "    event = df.loc[idx]\n",
    "    \n",
    "    # update widget values\n",
    "    idx_text.value = get_index_text(idx)\n",
    "    confidence_toggle.value = 'High'\n",
    "    triggers_widget.value = get_trigger_text(idx)\n",
    "    prev_input.value = 0\n",
    "    fwd_input.value = 0\n",
    "\n",
    "    # sentence_text = files[event.filename][event.idx]\n",
    "    with event_output:\n",
    "        event_output.clear_output()\n",
    "        \n",
    "        display_ent([nlp(files[event.filename][event.idx])])\n",
    "        \n",
    "    with prev_output:\n",
    "        prev_output.clear_output()\n",
    "        prev_output.layout.display = \"none\"\n",
    "\n",
    "    with fwd_output:\n",
    "        fwd_output.clear_output()\n",
    "        fwd_output.layout.display = \"none\"\n",
    "\n",
    "def save_pressed(b):\n",
    "    df.to_csv(labelled_path, index=True, index_label='index')\n",
    "\n",
    "idx_text = widgets.HTML(value=get_index_text(indices[i]))\n",
    "triggers_widget = widgets.HTML(value=get_trigger_text(indices[i]))\n",
    "line_break = widgets.HTML(value='\\n')\n",
    "\n",
    "prev_input = widgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=-10,\n",
    "    max=0,\n",
    "    step=1,\n",
    "    description='Previous',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "fwd_input = widgets.BoundedIntText(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Next',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def update_chunk(b):\n",
    "    global i\n",
    "    global prev\n",
    "    global fwd\n",
    "    \n",
    "    event = df.loc[indices[i]]\n",
    "    #triggers_widget.value = get_trigger_text(event.triggers)\n",
    "    \n",
    "    prev = prev_input.value\n",
    "    fwd = fwd_input.value\n",
    "\n",
    "    with prev_output:\n",
    "        if prev < 0:\n",
    "            prev_output.clear_output()\n",
    "            prev_chunk = list(nlp.pipe(files[event.filename][event.idx + prev : event.idx]))\n",
    "            display_ent(prev_chunk)\n",
    "            prev_output.layout.display = \"block\"\n",
    "        else:\n",
    "            prev_output.layout.display = 'none'\n",
    "        \n",
    "    with fwd_output:\n",
    "        if fwd > 0:\n",
    "            fwd_output.clear_output()\n",
    "            fwd_chunk = list(nlp.pipe(files[event.filename][event.idx + 1 : event.idx + 1 + fwd]))\n",
    "            display_ent(fwd_chunk)\n",
    "            fwd_output.layout.display = \"block\"\n",
    "        else:        \n",
    "            fwd_output.layout.display = 'none'\n",
    "\n",
    "def toggle_ner(toggle):\n",
    "    global idx\n",
    "    global prev\n",
    "    global fwd\n",
    "    \n",
    "    toggle = ner_toggle.get_interact_value()\n",
    "    \n",
    "    prev = prev_input.value\n",
    "    fwd = fwd_input.value\n",
    "    \n",
    "    if prev < 0:\n",
    "        with prev_output:\n",
    "            prev_chunk = list(nlp.pipe(files[event.filename][event.idx + prev : event.idx]))\n",
    "            if toggle:\n",
    "                prev_output.clear_output()\n",
    "                display_ent(prev_chunk)\n",
    "            else:\n",
    "                prev_chunk_text = ' '.join([token.text for token in prev_chunk]).strip()\n",
    "                prev_output.clear_output()\n",
    "                display(prev_chunk_text)\n",
    "                \n",
    "            prev_output.layout.display = \"block\"\n",
    "            \n",
    "    if fwd > 0:\n",
    "        with fwd_output:\n",
    "            fwd_chunk = list(nlp.pipe(files[event.filename][event.idx + 1 : event.idx + 1 + fwd]))\n",
    "            if toggle:\n",
    "                fwd_output.clear_output()\n",
    "                display_ent(fwd_chunk)\n",
    "            else:\n",
    "                fwd_chunk_text = ' '.join([token.text for token in fwd_chunk]).strip()\n",
    "                fwd_output.clear_output()\n",
    "                display(fwd_chunk_text)\n",
    "                \n",
    "            fwd_output.layout.display = \"block\"\n",
    "            \n",
    "prev_output = widgets.Output()\n",
    "event_output = widgets.Output()\n",
    "fwd_output = widgets.Output()\n",
    "\n",
    "prev_output.layout.display = \"none\"\n",
    "fwd_output.layout.display = \"none\"\n",
    "\n",
    "yes = widgets.Button(description='Near Miss Event', button_style='success')\n",
    "yes.on_click(yes_pressed)\n",
    "\n",
    "no = widgets.Button(description='Not Near Miss Event', button_style='danger')\n",
    "no.on_click(no_pressed)\n",
    "\n",
    "save = widgets.Button(description='Save DataFrame', button_style='primary')\n",
    "save.on_click(save_pressed)\n",
    "\n",
    "revert = widgets.Button(description='Revert Index', button_style='warning')\n",
    "revert.on_click(revert_pressed)\n",
    "\n",
    "update = widgets.Button(description='Update Text Range', button_style='')\n",
    "update.on_click(update_chunk)\n",
    "\n",
    "update_ner = widgets.Button(description='Update NER Display', button_style='')\n",
    "update_ner.on_click(toggle_ner)\n",
    "\n",
    "ner_toggle = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='External NER',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "confidence_toggle = widgets.ToggleButtons(\n",
    "    options=['Low', 'Medium', 'High'],\n",
    "    value='High',\n",
    "    description='Confidence',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltips=[\n",
    "        'An uncertain interpretation worth reviewing',\n",
    "        'A reasonable interpretation of a near miss',\n",
    "        'A certain interpretation of a near miss'],\n",
    ")\n",
    "\n",
    "save_chunk_toggle = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Save Text Chunk Bounds',\n",
    "    disabled=False,\n",
    "    #button_style='info',\n",
    "    #tooltip='Saves lower and upper bound indices on text chunks'\n",
    ")\n",
    "\n",
    "settings_text =  widgets.HTML(value=\"<h3>Text Chunk Settings</h3>\")\n",
    "labeller_text = widgets.HTML(value=\"<h3>Labeller</h3>\")\n",
    "\n",
    "#text_chunk_box = widgets.VBox([settings_text, save_chunk_toggle])\n",
    "\n",
    "text_buttons = widgets.HBox([update, save_chunk_toggle])\n",
    "ner_buttons = widgets.HBox([update_ner, ner_toggle])\n",
    "label_buttons = widgets.HBox([yes, no])\n",
    "function_buttons = widgets.HBox([save, revert])\n",
    "buttons = widgets.VBox([label_buttons, function_buttons])\n",
    "\n",
    "with event_output:\n",
    "    display_ent(nlp(files[event.filename][event.idx]))\n",
    "    \n",
    "with prev_output:\n",
    "    display(widgets.HTML(value='\\n'))\n",
    "\n",
    "with fwd_output:\n",
    "    display(widgets.HTML(value=''))\n",
    "                            \n",
    "display(idx_text, triggers_widget, settings_text, prev_input, fwd_input, text_buttons, ner_buttons,\n",
    "        labeller_text, buttons, line_break, confidence_toggle, prev_output, line_break, event_output, \n",
    "        line_break, fwd_output,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save backup\n",
    "df.to_csv(os.path.join('data','events',f'{user}_dataset_backup.csv'), index=True, index_label='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
